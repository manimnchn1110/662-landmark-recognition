{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mani/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cacf8152e2d2ae60</td>\n",
       "      <td>http://static.panoramio.com/photos/original/70...</td>\n",
       "      <td>4676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0a58358a2afd3e4e</td>\n",
       "      <td>http://lh6.ggpht.com/-igpT6wu0mIA/ROV8HnUuABI/...</td>\n",
       "      <td>6651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6b2bb500b6a38aa0</td>\n",
       "      <td>http://lh6.ggpht.com/-vKr5G5MEusk/SR6r6SJi6mI/...</td>\n",
       "      <td>11284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b399f09dee9c3c67</td>\n",
       "      <td>https://lh3.googleusercontent.com/-LOW2cjAqubA...</td>\n",
       "      <td>8429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19ace29d77a5be66</td>\n",
       "      <td>https://lh5.googleusercontent.com/-tnmSXwQcWL8...</td>\n",
       "      <td>6231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                                url  \\\n",
       "0  cacf8152e2d2ae60  http://static.panoramio.com/photos/original/70...   \n",
       "1  0a58358a2afd3e4e  http://lh6.ggpht.com/-igpT6wu0mIA/ROV8HnUuABI/...   \n",
       "2  6b2bb500b6a38aa0  http://lh6.ggpht.com/-vKr5G5MEusk/SR6r6SJi6mI/...   \n",
       "3  b399f09dee9c3c67  https://lh3.googleusercontent.com/-LOW2cjAqubA...   \n",
       "4  19ace29d77a5be66  https://lh5.googleusercontent.com/-tnmSXwQcWL8...   \n",
       "\n",
       "   landmark_id  \n",
       "0         4676  \n",
       "1         6651  \n",
       "2        11284  \n",
       "3         8429  \n",
       "4         6231  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First_100_train\n",
    "folder_path = './train' + '/'\n",
    "writer= tf.python_io.TFRecordWriter(\"Landmark_train.tfrecords\")\n",
    "for i in range(100):\n",
    "    img_path = folder_path + df.id[i] + '.jpeg'\n",
    "    output = int(df.landmark_id[i])\n",
    "    img=Image.open(img_path)\n",
    "    img_raw=img.tobytes()\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        \"label\": tf.train.Feature(int64_list=tf.train.Int64List(value=[output])),\n",
    "        'img_raw': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw]))\n",
    "    })) \n",
    "    writer.write(example.SerializeToString())\n",
    " \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_whole_sample_size = 100  \n",
    "test_whole_sample_size = 100 \n",
    "gesture_class = len(df.landmark_id[0:100].unique()) \n",
    "train_batch_size = 10  \n",
    "test_batch_size = 100  \n",
    "  \n",
    "image_size = 224\n",
    "train_path = \"./Landmark_train.tfrecords\"  \n",
    "\n",
    "graph_path = \"./tensorboard\"  \n",
    "\n",
    "cnn_model_save_path = \"./cnn_model/cnn_model.ckpt\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_decode(filename, batch_size, whole_sample_size):\n",
    "    global gesture_class, image_size\n",
    "    filename_queue = tf.train.string_input_producer([filename])  \n",
    "    reader = tf.TFRecordReader()  \n",
    "    _, serialized_example = reader.read(filename_queue)  \n",
    "    features = tf.parse_single_example(  \n",
    "        serialized_example,  \n",
    "        features={  \n",
    "            'label': tf.FixedLenFeature([], tf.int64),  \n",
    "            'img_raw': tf.FixedLenFeature([], tf.string),  \n",
    "        }  \n",
    "    )  \n",
    "    img = tf.decode_raw(features['img_raw'], tf.uint8)  # 原图数据二进制解码为 无符号8位整型  \n",
    "    img = tf.reshape(img, [image_size, image_size, 3])  # reshape 到原图size:28*28  \n",
    "    img = tf.cast(img, tf.float32) * (1. / 255.) - 0.5  # 数据归一化  \n",
    "    label = tf.cast(features['label'], tf.int64)  # 获取样本对应的标签  \n",
    "    img_batch, label_batch = tf.train.shuffle_batch([img, label],  \n",
    "                                                 batch_size=batch_size,  \n",
    "                                                 capacity=whole_sample_size,  \n",
    "                                                 min_after_dequeue=50,  \n",
    "                                                 num_threads=2  # 线程数  \n",
    "                                                 )  \n",
    "    return img_batch,label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train set\n",
    "img_train_batch, labels_train_batch = read_and_decode(train_path, train_batch_size, train_whole_sample_size)  \n",
    "train_label = tf.one_hot(labels_train_batch, gesture_class, 1, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test set\n",
    "img_test_batch, labels_test_batch = read_and_decode(train_path, test_batch_size, test_whole_sample_size) \n",
    "test_label = tf.one_hot(labels_test_batch, gesture_class, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create graph placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, image_size, image_size, 3], name=\"images\")\n",
    "y = tf.placeholder(tf.float32, shape=[None, gesture_class,], name=\"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape, f_name):  \n",
    "    initial = tf.truncated_normal(shape, mean=0, stddev=0.1)\n",
    "    return tf.Variable(initial, name=f_name)  \n",
    "\n",
    "def bias_variable(shape, f_name):  \n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial, name=f_name)  \n",
    "  \n",
    "def Conv2d_Filter(x, W):  \n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=\"SAME\")  \n",
    "  \n",
    "def max_pooling_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1)Layer 1: conv 3x3 64 (RELU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input: 224x224x3\n",
    "- Type: Conv\n",
    "- size: 3x3\n",
    "- channel: 64\n",
    "- strides: 1\n",
    "- Output: 224x224x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Conv1'):  \n",
    "    W_conv1 = weight_variable([3,3,3,64], 'W_conv1')\n",
    "    b_conv1 = bias_variable([64], 'b_conv1')\n",
    "    with tf.name_scope('h_conv1'):  \n",
    "        h_conv1 = tf.nn.relu(Conv2d_Filter(x, W_conv1) + b_conv1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2)Layer 1: max pooling 2x2 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input: 224x224x64\n",
    "- pool: 2x2\n",
    "- output: 112x112x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Pool1'):  \n",
    "    h_pool1 = max_pooling_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3)Layer 2: conv 3x3 128 (RELU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input: 112x112x64\n",
    "- Type: Conv\n",
    "- size: 3x3\n",
    "- channel: 128\n",
    "- strides: 1\n",
    "- Output: 112x112x128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Conv2'):  \n",
    "    W_conv2 = weight_variable([3,3,64,128], 'W_conv2')\n",
    "    b_conv2 = bias_variable([128], 'b_conv2')\n",
    "    with tf.name_scope('h_conv2'):\n",
    "        h_conv2 = tf.nn.relu(Conv2d_Filter(h_pool1, W_conv2) + b_conv2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4)Layer 2: max pooling 2x2 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input: 112x112x128\n",
    "- pool: 2x2\n",
    "- output: 56x56x128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Pool2'):  \n",
    "    h_pool2 = max_pooling_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5)Layer 3: conv 3x3 256 (RELU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input: 56x56x128\n",
    "- Type: Conv\n",
    "- size: 3x3\n",
    "- channel: 256\n",
    "- strides: 1\n",
    "- Output: 56x56x256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Conv3'):  \n",
    "    W_conv3 = weight_variable([3,3,128,256], 'W_conv3')\n",
    "    b_conv3 = bias_variable([256], 'b_conv3')\n",
    "    with tf.name_scope('h_conv3'):\n",
    "        h_conv3 = tf.nn.relu(Conv2d_Filter(h_pool2, W_conv3) + b_conv3)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6)Layer 3: max pooling 2x2 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input: 56x56x256\n",
    "- pool: 2x2\n",
    "- output: 28x28x256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Pool3'):  \n",
    "    h_pool3 = max_pooling_2x2(h_conv3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7)Layer 4: conv 3x3 512 (RELU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input: 28x28x256\n",
    "- Type: Conv\n",
    "- size: 3x3\n",
    "- channel: 512\n",
    "- strides: 1\n",
    "- Output: 28x28x512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Conv4'):  \n",
    "    W_conv4 = weight_variable([3,3,256,512], 'W_conv4')\n",
    "    b_conv4 = bias_variable([512], 'b_conv4')\n",
    "    with tf.name_scope('h_conv4'):\n",
    "        h_conv4 = tf.nn.relu(Conv2d_Filter(h_pool3, W_conv4) + b_conv4)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8)Layer 4: max pooling 2x2 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input: 28x28x512\n",
    "- pool: 2x2\n",
    "- output: 14x14x512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Pool4'):  \n",
    "    h_pool4 = max_pooling_2x2(h_conv4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9)Layer 5: conv 3x3 512 (RELU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input: 14x14x512\n",
    "- Type: Conv\n",
    "- size: 3x3\n",
    "- channel: 512\n",
    "- strides: 1\n",
    "- Output: 14x14x512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Conv5'):  \n",
    "    W_conv5 = weight_variable([3,3,512,512], 'W_conv5')\n",
    "    b_conv5 = bias_variable([512], 'b_conv5')\n",
    "    with tf.name_scope('h_conv5'):\n",
    "        h_conv5 = tf.nn.relu(Conv2d_Filter(h_pool4, W_conv5) + b_conv5)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10)Layer 5: max pooling 2x2 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input: 14x14x512\n",
    "- pool: 2x2\n",
    "- output: 7x7x512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Pool5'):  \n",
    "    h_pool5 = max_pooling_2x2(h_conv5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11)Layer 6: Fully Connected Layer 4096 (ReLU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reshape:[1, 7x7x512 = 25088]\n",
    "output: [1, 4096]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12)Layer 7: Fully Connected Layer - Dropout Layer (reducing overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Fc1'):  \n",
    "    W_fc1 = weight_variable([25088, 4096], 'W_fc1')\n",
    "    b_fc1 = bias_variable([4096], 'b_fc1')\n",
    "\n",
    "    with tf.name_scope('Pool5_flat'):  \n",
    "        h_pool5_flat = tf.reshape(h_pool5, [-1, 25088])  \n",
    "\n",
    "    with tf.name_scope('h_fc1'):  \n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool5_flat, W_fc1) + b_fc1)  \n",
    "        \n",
    "    keep_prob = tf.placeholder(tf.float32, name=\"my_keep_prob\")  \n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob, name=\"my_h_fc1_drop\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  13)Layer 8: Readout Layer (Softmax Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Fc2'):  \n",
    "    # 第二个全连接层  \n",
    "    W_fc2 = weight_variable([4096, gesture_class], 'W_fc2')  \n",
    "    b_fc2 = bias_variable([gesture_class], 'b_fc2')  \n",
    "  \n",
    "    with tf.name_scope('softmax'):  \n",
    "        prediction = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2, name=\"my_prediction\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions and train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type of optimization: Gradient Descent\n",
    "- Training process：\n",
    "1. Calculate Error Rate（corss_entropy）\n",
    "2. Reduce Error Rate\n",
    "3. Revised Kernels's weight to reduce Error Rate (corss_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Corss_Entropy'):  \n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=prediction),  \n",
    "                                   name=\"loss\")\n",
    "    tf.summary.scalar('corss_entropy', cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Train_step'):  \n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy, name=\"train_step\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define prediction\n",
    "计算有多少的案例成功预测，多少未成功"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.arg_max(prediction, 1), tf.arg_max(y, 1))  \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))  \n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 0 times training.\n",
      "Itsers = 0  Accuracy: 0.0\n",
      "The 1 times training.\n",
      "Itsers = 1  Accuracy: 0.0\n",
      "The 2 times training.\n",
      "Itsers = 2  Accuracy: 0.0\n",
      "The 3 times training.\n",
      "Itsers = 3  Accuracy: 0.0\n",
      "The 4 times training.\n",
      "Itsers = 4  Accuracy: 0.0\n",
      "The 5 times training.\n",
      "Itsers = 5  Accuracy: 0.0\n",
      "The 6 times training.\n",
      "Itsers = 6  Accuracy: 0.0\n",
      "The 7 times training.\n",
      "Itsers = 7  Accuracy: 0.0\n",
      "The 8 times training.\n",
      "Itsers = 8  Accuracy: 0.0\n",
      "The 9 times training.\n",
      "Itsers = 9  Accuracy: 0.0\n",
      "The 10 times training.\n",
      "Itsers = 10  Accuracy: 0.0\n",
      "The 11 times training.\n",
      "Itsers = 11  Accuracy: 0.0\n",
      "The 12 times training.\n",
      "Itsers = 12  Accuracy: 0.0\n",
      "The 13 times training.\n",
      "Itsers = 13  Accuracy: 0.0\n",
      "The 14 times training.\n",
      "Itsers = 14  Accuracy: 0.0\n",
      "The 15 times training.\n",
      "Itsers = 15  Accuracy: 0.0\n",
      "The 16 times training.\n",
      "Itsers = 16  Accuracy: 0.0\n",
      "The 17 times training.\n",
      "Itsers = 17  Accuracy: 0.0\n",
      "The 18 times training.\n",
      "Itsers = 18  Accuracy: 0.0\n",
      "The 19 times training.\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled\n",
      "\t [[Node: input_producer_3/input_producer_3_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_producer_3, input_producer_3/RandomShuffle)]]\n",
      "\n",
      "Caused by op 'input_producer_3/input_producer_3_EnqueueMany', defined at:\n",
      "  File \"/Users/mani/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Users/mani/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/mani/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/mani/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/mani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/Users/mani/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/Users/mani/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/Users/mani/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/mani/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/Users/mani/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/Users/mani/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/Users/mani/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/mani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/Users/mani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/Users/mani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/Users/mani/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/mani/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/mani/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/Users/mani/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/Users/mani/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-10-342a542bf761>\", line 2, in <module>\n",
      "    img_test_batch, labels_test_batch = read_and_decode(train_path, test_batch_size, test_whole_sample_size)\n",
      "  File \"<ipython-input-6-4a5a320bf859>\", line 3, in read_and_decode\n",
      "    filename_queue = tf.train.string_input_producer([filename])\n",
      "  File \"/Users/mani/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/input.py\", line 232, in string_input_producer\n",
      "    cancel_op=cancel_op)\n",
      "  File \"/Users/mani/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/input.py\", line 164, in input_producer\n",
      "    enq = q.enqueue_many([input_tensor])\n",
      "  File \"/Users/mani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/data_flow_ops.py\", line 367, in enqueue_many\n",
      "    self._queue_ref, vals, name=scope)\n",
      "  File \"/Users/mani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 1556, in _queue_enqueue_many_v2\n",
      "    name=name)\n",
      "  File \"/Users/mani/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n",
      "    op_def=op_def)\n",
      "  File \"/Users/mani/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n",
      "    original_op=self._default_original_op, op_def=op_def)\n",
      "  File \"/Users/mani/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n",
      "    self._traceback = _extract_stack()\n",
      "\n",
      "CancelledError (see above for traceback): Enqueue operation was cancelled\n",
      "\t [[Node: input_producer_3/input_producer_3_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_producer_3, input_producer_3/RandomShuffle)]]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-067a497a2a84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"times training.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mimg_test_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_test_xs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_test_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 读取测试 batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimg_test_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabel_test_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Itsers = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"  Accuracy: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())  \n",
    "        \n",
    "    train_writer = tf.summary.FileWriter(graph_path, sess.graph);\n",
    "  \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n",
    "  \n",
    "    saver = tf.train.Saver()\n",
    "    max_acc = 0\n",
    "  \n",
    "    for i in range(100):  \n",
    "  \n",
    "        img_xs, label_xs = sess.run([img_train_batch, train_label]) \n",
    "        sess.run(train_step, feed_dict={x: img_xs, y: label_xs, keep_prob: 0.75})  \n",
    "  \n",
    "        if (i % 1) == 0:  \n",
    "            print(\"The\", i, \"times training.\")  \n",
    "            img_test_xs, label_test_xs = sess.run([img_test_batch, test_label])  # 读取测试 batch  \n",
    "            acc = accuracy.eval(feed_dict={x:{x: img_test_xs, y: label_test_xs, keep_prob: 1.0})  \n",
    "            print(\"Itsers = \" + str(i) + \"  Accuracy: \" + str(acc))  \n",
    "            \n",
    "            summay = sess.run(merged, feed_dict={x: img_test_xs, y: label_test_xs, keep_prob: 1})  \n",
    "            \n",
    "            train_writer.add_summary(summay, i)  \n",
    "            \n",
    "  \n",
    "            #if max_acc < acc:\n",
    "                #max_acc = acc  \n",
    "            saver.save(sess, save_path=cnn_model_save_path)  \n",
    "  \n",
    "            if acc > 0.50:\n",
    "                break  \n",
    "  \n",
    "    train_writer.close()  \n",
    "  \n",
    "    coord.request_stop()  \n",
    "    coord.join(threads)  \n",
    "    sess.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
